run_name: OLMo-speed-test
seed: 42
dry_run: false

wandb: null  # Disable wandb for speed test

model:
  d_model: 256
  n_heads: 8
  n_layers: 8
  mlp_ratio: 8
  weight_tying: false
  alibi: false
  rope: true
  flash_attention: true
  attention_dropout: 0.0
  attention_layer_norm: false
  clip_qkv: null
  include_bias: false
  block_type: sequential
  layer_norm_type: rms
  layer_norm_with_affine: true
  layer_norm_eps: 1e-6
  bias_for_layer_norm: false
  attention_layer_norm_with_affine: false
  activation_type: swiglu
  residual_dropout: 0.0
  embedding_dropout: 0.0
  max_sequence_length: 2048
  vocab_size: 50257
  embedding_size: 50304
  eos_token_id: 50256
  pad_token_id: 50256
  init_device: cuda
  init_fn: normal
  init_std: 0.02
  init_cutoff_factor: 3

compile: null

optimizer:
  name: adamw
  learning_rate: 6.0e-4
  weight_decay: 0.1
  eps: 1e-8
  decay_norm_and_bias: true
  decay_embeddings: true
  betas:
  - 0.9
  - 0.95
  metrics_log_interval: 10

scheduler:
  name: cosine_with_warmup
  t_warmup: 100
  alpha_f: 0.1
  warmup_min_lr: 0

tokenizer:
  identifier: gpt2
  truncate_direction: right

save_folder: /tmp/olmo-speed-test
save_overwrite: true
save_interval: 1000  # Don't save during speed test
save_num_checkpoints_to_keep: 0

# Unsharded checkpoints (for single GPU)
save_interval_unsharded: 1000
save_num_unsharded_checkpoints_to_keep: 0

no_pre_train_checkpoint: true

load_path: null

max_duration: 100  # 100 steps for speed test
global_train_batch_size: 8
device_train_microbatch_size: 8

precision: amp_bf16
distributed_strategy: single

gen1_gc_interval: 1

max_grad_norm: 1.0

speed_monitor:
  window_size: 20

data:
  paths:
    - /home/vec_norm/OLMo/data/c4-sample/0_00000.npy
    - /home/vec_norm/OLMo/data/c4-sample/1_00000.npy
    - /home/vec_norm/OLMo/data/c4-sample/2_00000.npy
  num_workers: 2
  prefetch_factor: 2
  persistent_workers: true
  drop_last: true

evaluators: []

